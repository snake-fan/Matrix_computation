\documentclass{article}

\title{\Huge Matrix Computation Homework 1}
\author{\normalsize Yifan Zhang  2025251018  zhangyf52025@shanghaitech.edu.cn}

% import peckage
\usepackage{indentfirst}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{array}
\usepackage{mathtools}

\newcommand{\madj}{\mathop{\mathrm{adj}}}
\newcommand{\trace}{\mathop{\mathrm{tr}}}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclarePairedDelimiter{\pnorm}{\lVert}{\rVert_p}

% special letters
\newcommand{\x}{{\mathbf{x}}} % vector x
\newcommand{\y}{{\mathbf{y}}} % vector y
\newcommand{\z}{{\mathbf{z}}} % vector z
\newcommand{\0}{{\mathbf{0}}} % zero vector

\newcommand{\A}{{\mathbf{A}}} % matrix A
\newcommand{\B}{{\mathbf{B}}} % matrix B
\newcommand{\matC}{{\mathbf{C}}} % matrix C
\newcommand{\matD}{{\mathbf{D}}} % matrix D
\newcommand{\matE}{{\mathbf{E}}} % matrix E
\newcommand{\matH}{{\mathbf{H}}} % matrix H
\newcommand{\matK}{{\mathbf{K}}} % matrix K
\newcommand{\X}{{\mathbf{X}}} % matrix X
\newcommand{\Y}{{\mathbf{Y}}} % matrix Y
\newcommand{\Z}{{\mathbf{Z}}} % matrix Z
\newcommand{\M}{{\mathbf{M}}} % matrix M
\newcommand{\I}{{\mathbf{I}}} % identity matrix

\newcommand{\calV}{{\mathcal{V}}} % subspace V
\newcommand{\calU}{{\mathcal{U}}} % subspace U
\newcommand{\calS}{{\mathcal{S}}} % subspace S
\newcommand{\calM}{{\mathcal{M}}} % subspace M
\newcommand{\calN}{{\mathcal{N}}} % subspace N
\newcommand{\calR}{\mathop{\mathcal{R}}} % range
\renewcommand{\calN}{\mathop{\mathcal{N}}} % nullspace

% number fields
\newcommand{\R}{\mathbb{R}} % real numbers
\newcommand{\C}{\mathbb{C}} % complex numbers

\newcommand{\bigO}{{\mathcal{O}}} % big-Oh notation

\newcommand{\vect}[1]{\mathbf{#1}}

\begin{document}
\maketitle

\section*{Problem 1. (Discrete-Time LTI Systems)}

\subsection*{1)}

\textbf{Task}: Assuming $p=2$ and no noise, solve for the matrix $\mathbf{A}$ in $\mathbf{y} = \mathbf{A}\mathbf{x}$.

According to the problem description, $\mathbf{A}$ is a convolution matrix constructed from $h[n] = [h_0, h_1, h_2]$. $\mathbf{y} = \mathbf{A}\mathbf{x}$ describes the linear convolution $y[n] = x[n] * h[n]$.

\[
y[n] = \sum_{k=0}^{p} h[k] \cdot x[n-k] = h_0 x[n] + h_1 x[n-1] + h_2 x[n-2]
\]

We know $\mathbf{x} = [ 1, 0, 1, 0, 1, 1, 0, 1]$ and $\mathbf{y} = [1, 2, 4, 2, 4, 3, 5, 4]$. Since there is no noise, we can directly solve for $h_0, h_1, h_2$ using the first few outputs.

\begin{enumerate}
    \item \textbf{Solving for $h_0$}:
    \[
    y[0] = h_0 x[0] + h_1 x[-1] + h_2 x[-2]
    \]
    According to the problem, $x[n<0] = 0$, so:
    \[
    y[0] = h_0 x[0]
    \]
    \[
    1 = h_0 \cdot 1 \implies \mathbf{h_0 = 1}
    \]

    \item \textbf{Solving for $h_1$}:
    \[
    y[1] = h_0 x[1] + h_1 x[0] + h_2 x[-1]
    \]
    \[
    y[1] = h_0 x[1] + h_1 x[0]
    \]
    \[
    2 = (1) \cdot (0) + h_1 \cdot (1) \implies \mathbf{h_1 = 2}
    \]

    \item \textbf{Solving for $h_2$}:
    \[
    y[2] = h_0 x[2] + h_1 x[1] + h_2 x[0]
    \]
    \[
    4 = (1) \cdot (1) + (2) \cdot (0) + h_2 \cdot (1)
    \]
    \[
    4 = 1 + h_2 \implies \mathbf{h_2 = 3}
    \]
\end{enumerate}

We have obtained the channel impulse response $\mathbf{h} = [1, 2, 3]^T$.

Now, we construct the $8 \times 8$ linear convolution matrix $\mathbf{A}$ based on this $\mathbf{h}$. $\mathbf{A}$ is a lower triangular Toeplitz matrix:
\[
\mathbf{A} =
\begin{pmatrix}
h_0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
h_1 & h_0 & 0 & 0 & 0 & 0 & 0 & 0 \\
h_2 & h_1 & h_0 & 0 & 0 & 0 & 0 & 0 \\
0 & h_2 & h_1 & h_0 & 0 & 0 & 0 & 0 \\
0 & 0 & h_2 & h_1 & h_0 & 0 & 0 & 0 \\
0 & 0 & 0 & h_2 & h_1 & h_0 & 0 & 0 \\
0 & 0 & 0 & 0 & h_2 & h_1 & h_0 & 0 \\
0 & 0 & 0 & 0 & 0 & h_2 & h_1 & h_0
\end{pmatrix}
\]
Substituting $h_0=1, h_1=2, h_2=3$, we solve for $\mathbf{A}$ as:
\[
\mathbf{A} =
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
3 & 2 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 3 & 2 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 3 & 2 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 3 & 2 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 3 & 2 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 3 & 2 & 1
\end{pmatrix}
\]
The full equation for $\mathbf{y} = \mathbf{A}\mathbf{x}$ is as follows:
\[
\begin{pmatrix} 1 \\ 2 \\ 4 \\ 2 \\ 4 \\ 3 \\ 5 \\ 4 \end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
3 & 2 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 3 & 2 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 3 & 2 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 3 & 2 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 3 & 2 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 3 & 2 & 1
\end{pmatrix}
\begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 1 \\ 0 \\ 1 \end{pmatrix}
\]

\subsection*{b)}

\textbf{Task}: Solve for $\hat{\mathbf{h}}$ by minimizing the error $\|\mathbf{y} - \mathbf{C}\hat{\mathbf{h}}\|^2$.

This is a standard Least Squares (LS) problem. Here, $\mathbf{y} = \mathbf{C}\hat{\mathbf{h}}$, where $\mathbf{C}$ is the convolution matrix constructed from the input $\mathbf{x}$, and $\hat{\mathbf{h}}$ is the channel response vector we want to estimate.

\begin{enumerate}
    \item \textbf{Constructing the matrix $\mathbf{C}$} \\
    $\hat{\mathbf{h}} = [h_0, h_1, h_2]^T$ is a $3 \times 1$ vector.
    $\mathbf{y}$ is an $8 \times 1$ vector.
    $\mathbf{C}$ must be an $8 \times 3$ matrix of the following form:
    \[
    \mathbf{C} =
    \begin{pmatrix}
    x[0] & x[-1] & x[-2] \\
    x[1] & x[0] & x[-1] \\
    x[2] & x[1] & x[0] \\
    x[3] & x[2] & x[1] \\
    x[4] & x[3] & x[2] \\
    x[5] & x[4] & x[3] \\
    x[6] & x[5] & x[4] \\
    x[7] & x[6] & x[5]
    \end{pmatrix}
    \]
    Substituting $\mathbf{x} = [ 1, 0, 1, 0, 1, 1, 0, 1]$ and $x[n<0]=0$:
    \[
    \mathbf{C} =
    \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    1 & 0 & 1 \\
    0 & 1 & 0 \\
    1 & 0 & 1 \\
    1 & 1 & 0 \\
    0 & 1 & 1 \\
    1 & 0 & 1
    \end{pmatrix}
    \]

    \item \textbf{Setting up the Normal Equations} \\
    The least-squares solution $\hat{\mathbf{h}}$ is given by the normal equations:
    \[
    (\mathbf{C}^T \mathbf{C}) \hat{\mathbf{h}} = \mathbf{C}^T \mathbf{y}
    \]

    \item \textbf{Calculating $\mathbf{C}^T \mathbf{C}$}
    \[
    \mathbf{C}^T =
    \begin{pmatrix}
    1 & 0 & 1 & 0 & 1 & 1 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 \\
    0 & 0 & 1 & 0 & 1 & 0 & 1 & 1
    \end{pmatrix}
    \]
    \[
    \mathbf{C}^T \mathbf{C} =
    \begin{pmatrix}
    1 & 0 & 1 & 0 & 1 & 1 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 \\
    0 & 0 & 1 & 0 & 1 & 0 & 1 & 1
    \end{pmatrix}
    \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    1 & 0 & 1 \\
    0 & 1 & 0 \\
    1 & 0 & 1 \\
    1 & 1 & 0 \\
    0 & 1 & 1 \\
    1 & 0 & 1
    \end{pmatrix}
    =
    \begin{pmatrix}
    5 & 1 & 3 \\
    1 & 4 & 1 \\
    3 & 1 & 4
    \end{pmatrix}
    \]

    \item \textbf{Calculating $\mathbf{C}^T \mathbf{y}$}
    \[
    \mathbf{C}^T \mathbf{y} =
    \begin{pmatrix}
    1 & 0 & 1 & 0 & 1 & 1 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 \\
    0 & 0 & 1 & 0 & 1 & 0 & 1 & 1
    \end{pmatrix}
    \begin{pmatrix}
    1 \\ 2 \\ 4 \\ 2 \\ 4 \\ 3 \\ 5 \\ 4
    \end{pmatrix}
    =
    \begin{pmatrix}
    1+0+4+0+4+3+0+4 \\
    0+2+0+2+0+3+5+0 \\
    0+0+4+0+4+0+5+4
    \end{pmatrix}
    =
    \begin{pmatrix}
    16 \\
    12 \\
    17
    \end{pmatrix}
    \]

    \item \textbf{Solving for $\hat{\mathbf{h}}$} \\
    We now need to solve the linear system:
    \[
    \begin{pmatrix}
    5 & 1 & 3 \\
    1 & 4 & 1 \\
    3 & 1 & 4
    \end{pmatrix}
    \begin{pmatrix}
    h_0 \\ h_1 \\ h_2
    \end{pmatrix}
    =
    \begin{pmatrix}
    16 \\
    12 \\
    17
    \end{pmatrix}
    \]
    As shown in (a), since this is a no-noise example, the solution $\hat{\mathbf{h}} = [1, 2, 3]^T$ obtained from (a) should satisfy this system. Let's verify:
    \begin{itemize}
        \item (1) $5(1) + 1(2) + 3(3) = 5 + 2 + 9 = 16$ (Holds)
        \item (2) $1(1) + 4(2) + 1(3) = 1 + 8 + 3 = 12$ (Holds)
        \item (3) $3(1) + 1(2) + 4(3) = 3 + 2 + 12 = 17$ (Holds)
    \end{itemize}
    The solution to the system is unique, therefore the least-squares estimate $\hat{\mathbf{h}}$ is:
    \[
    \hat{\mathbf{h}} = \begin{pmatrix} h_0 \\ h_1 \\ h_2 \end{pmatrix} = \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}
    \]
\end{enumerate}


\noindent \textbf{Solution.}


\section*{Problem 2. (Gram-Schmidt Procedure) }
\subsection*{1) QR Decomposition of $\mathbf{A}_1$ (Classical Gram-Schmidt)}

Given $\mathbf{A}_1 = [\mathbf{a}_1, \mathbf{a}_2, \mathbf{a}_3]$:
\[
\mathbf{A}_1 = \begin{bmatrix} 1 & 0 & 3 \\ 1 & 2 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}
\]

\textbf{Step 1: Compute $\mathbf{q}_1$}
\[
r_{11} = \|\mathbf{a}_1\|_2 = \sqrt{1^2 + 1^2 + 1^2 + 1^2} = 2
\]
\[
\mathbf{q}_1 = \frac{\mathbf{a}_1}{r_{11}} = \begin{bmatrix} 0.5 \\ 0.5 \\ 0.5 \\ 0.5 \end{bmatrix}
\]

\textbf{Step 2: Compute $\mathbf{q}_2$}
\[
r_{12} = \mathbf{q}_1^T \mathbf{a}_2 = 0.5(0) + 0.5(2) + 0.5(1) + 0.5(1) = 2
\]
\[
\mathbf{v}_2 = \mathbf{a}_2 - r_{12}\mathbf{q}_1 = \begin{bmatrix} 0 \\ 2 \\ 1 \\ 1 \end{bmatrix} - 2\begin{bmatrix} 0.5 \\ 0.5 \\ 0.5 \\ 0.5 \end{bmatrix} = \begin{bmatrix} -1 \\ 1 \\ 0 \\ 0 \end{bmatrix}
\]
\[
r_{22} = \|\mathbf{v}_2\|_2 = \sqrt{(-1)^2 + 1^2} = \sqrt{2}
\]
\[
\mathbf{q}_2 = \frac{\mathbf{v}_2}{r_{22}} = \begin{bmatrix} -1/\sqrt{2} \\ 1/\sqrt{2} \\ 0 \\ 0 \end{bmatrix}
\]

\textbf{Step 3: Compute $\mathbf{q}_3$}
\[
r_{13} = \mathbf{q}_1^T \mathbf{a}_3 = 3
\]
\[
r_{23} = \mathbf{q}_2^T \mathbf{a}_3 = \frac{1}{\sqrt{2}}(-3 + 1) = -\sqrt{2}
\]
\[
\mathbf{v}_3 = \mathbf{a}_3 - r_{13}\mathbf{q}_1 - r_{23}\mathbf{q}_2 
= \begin{bmatrix} 3 \\ 1 \\ 1 \\ 1 \end{bmatrix} - \begin{bmatrix} 1.5 \\ 1.5 \\ 1.5 \\ 1.5 \end{bmatrix} - \begin{bmatrix} 1 \\ -1 \\ 0 \\ 0 \end{bmatrix} 
= \begin{bmatrix} 0.5 \\ 0.5 \\ -0.5 \\ -0.5 \end{bmatrix}
\]
\[
r_{33} = \|\mathbf{v}_3\|_2 = 1
\]
\[
\mathbf{q}_3 = \begin{bmatrix} 0.5 \\ 0.5 \\ -0.5 \\ -0.5 \end{bmatrix}
\]

\textbf{Result:}
\[
\mathbf{Q} = \begin{bmatrix} 0.5 & -1/\sqrt{2} & 0.5 \\ 0.5 & 1/\sqrt{2} & 0.5 \\ 0.5 & 0 & -0.5 \\ 0.5 & 0 & -0.5 \end{bmatrix}, \quad 
\mathbf{R} = \begin{bmatrix} 2 & 2 & 3 \\ 0 & \sqrt{2} & -\sqrt{2} \\ 0 & 0 & 1 \end{bmatrix}
\]

\newpage

\subsection*{2) QR Decomposition of $\mathbf{A}_1$ (Modified Gram-Schmidt)}

The Modified Gram-Schmidt (MGS) procedure updates the vectors iteratively to improve numerical stability.

\textbf{Initialization}
Let $\mathbf{v}_1 = \mathbf{a}_1, \mathbf{v}_2 = \mathbf{a}_2, \mathbf{v}_3 = \mathbf{a}_3$.

\textbf{Step 1}
\[ r_{11} = \|\mathbf{v}_1\| = 2, \quad \mathbf{q}_1 = \mathbf{v}_1 / 2 = [0.5, 0.5, 0.5, 0.5]^T \]
Update $\mathbf{v}_2, \mathbf{v}_3$:
\[ r_{12} = \mathbf{q}_1^T \mathbf{v}_2 = 2 \implies \mathbf{v}_2^{(2)} = \mathbf{v}_2 - r_{12}\mathbf{q}_1 = [-1, 1, 0, 0]^T \]
\[ r_{13} = \mathbf{q}_1^T \mathbf{v}_3 = 3 \implies \mathbf{v}_3^{(2)} = \mathbf{v}_3 - r_{13}\mathbf{q}_1 = [1.5, -0.5, -0.5, -0.5]^T \]

\textbf{Step 2}
\[ r_{22} = \|\mathbf{v}_2^{(2)}\| = \sqrt{2}, \quad \mathbf{q}_2 = \mathbf{v}_2^{(2)} / \sqrt{2} = [-1/\sqrt{2}, 1/\sqrt{2}, 0, 0]^T \]
Update $\mathbf{v}_3$:
\[ r_{23} = \mathbf{q}_2^T \mathbf{v}_3^{(2)} = -\sqrt{2} \]
\[ \mathbf{v}_3^{(3)} = \mathbf{v}_3^{(2)} - r_{23}\mathbf{q}_2 = [0.5, 0.5, -0.5, -0.5]^T \]

\textbf{Step 3}
\[ r_{33} = \|\mathbf{v}_3^{(3)}\| = 1, \quad \mathbf{q}_3 = [0.5, 0.5, -0.5, -0.5]^T \]

\textbf{Result:} The matrices $\mathbf{Q}$ and $\mathbf{R}$ are identical to those in Problem 1.

\subsection*{3) QR Decomposition of $\mathbf{A}_2$}

Given $\mathbf{A}_2 = [\mathbf{a}_1, \mathbf{a}_2, \mathbf{a}_3, \mathbf{a}_4]$ with rank 3. We compute $\mathbf{Q} \in \mathbb{R}^{6 \times 3}$ and $\mathbf{R} \in \mathbb{R}^{3 \times 4}$.

\textbf{Processing Columns}
\begin{enumerate}
    \item \textbf{Vector $\mathbf{a}_1$:} $\|\mathbf{a}_1\| = 2$. 
    \[ \mathbf{q}_1 = [0.5, 0.5, 0, 0, 0.5, 0.5]^T, \quad r_{11}=2 \]
    
    \item \textbf{Vector $\mathbf{a}_2$:} $r_{12} = \mathbf{q}_1^T \mathbf{a}_2 = 1$.
    \[ \mathbf{v}_2 = \mathbf{a}_2 - \mathbf{q}_1 = [-0.5, 0.5, 0, 1, 0.5, -0.5]^T, \quad \|\mathbf{v}_2\|=\sqrt{2} \]
    \[ \mathbf{q}_2 = \frac{1}{\sqrt{2}}[-0.5, 0.5, 0, 1, 0.5, -0.5]^T, \quad r_{22}=\sqrt{2} \]
    
    \item \textbf{Vector $\mathbf{a}_3$:} Note $\mathbf{a}_3 = 3\mathbf{a}_1 + \mathbf{a}_2$.
    \[ r_{13} = \mathbf{q}_1^T \mathbf{a}_3 = 7, \quad r_{23} = \mathbf{q}_2^T \mathbf{a}_3 = \sqrt{2} \]
    Residue $\mathbf{v}_3 = \mathbf{a}_3 - 7\mathbf{q}_1 - \sqrt{2}\mathbf{q}_2 = \mathbf{0}$. Thus, no new basis vector is formed.
    
    \item \textbf{Vector $\mathbf{a}_4$:} 
    \[ r_{14} = \mathbf{q}_1^T \mathbf{a}_4 = 1.5 \]
    \[ r_{24} = \mathbf{q}_2^T \mathbf{a}_4 = \frac{1}{\sqrt{2}}(0.5) = \frac{1}{2\sqrt{2}} \]
    \[ \mathbf{v}_4 = \mathbf{a}_4 - 1.5\mathbf{q}_1 - \frac{1}{2\sqrt{2}}\mathbf{q}_2 = \frac{1}{8}[3, 1, 8, -2, 1, -5]^T \]
    \[ r_{34} = \|\mathbf{v}_4\| = \frac{\sqrt{26}}{4} \]
    \[ \mathbf{q}_3 = \frac{\mathbf{v}_4}{r_{34}} = \frac{1}{2\sqrt{26}}[3, 1, 8, -2, 1, -5]^T \]
\end{enumerate}

\textbf{Result:}
\[
\mathbf{Q} = \begin{bmatrix} 0.5 & \frac{-1}{2\sqrt{2}} & \frac{3}{2\sqrt{26}} \\ 0.5 & \frac{1}{2\sqrt{2}} & \frac{1}{2\sqrt{26}} \\ 0 & 0 & \frac{8}{2\sqrt{26}} \\ 0 & \frac{1}{\sqrt{2}} & \frac{-2}{2\sqrt{26}} \\ 0.5 & \frac{1}{2\sqrt{2}} & \frac{1}{2\sqrt{26}} \\ 0.5 & \frac{-1}{2\sqrt{2}} & \frac{-5}{2\sqrt{26}} \end{bmatrix}, \quad
\mathbf{R} = \begin{bmatrix} 2 & 1 & 7 & 1.5 \\ 0 & \sqrt{2} & \sqrt{2} & \frac{\sqrt{2}}{4} \\ 0 & 0 & 0 & \frac{\sqrt{26}}{4} \end{bmatrix}
\]

\subsection*{4) Least Squares Solution}

Solve $\mathbf{A}_1\mathbf{x} = \mathbf{b}$ where $\mathbf{b} = [4, 0, 4, 0]^T$.
Using $\mathbf{R}\mathbf{x} = \mathbf{Q}^T\mathbf{b}$:

\[
\mathbf{Q}^T\mathbf{b} = \begin{bmatrix} \mathbf{q}_1^T\mathbf{b} \\ \mathbf{q}_2^T\mathbf{b} \\ \mathbf{q}_3^T\mathbf{b} \end{bmatrix} = \begin{bmatrix} 0.5(4)+0+0.5(4)+0 \\ \frac{-1}{\sqrt{2}}(4)+0+0+0 \\ 0.5(4)+0-0.5(4)+0 \end{bmatrix} = \begin{bmatrix} 4 \\ -2\sqrt{2} \\ 0 \end{bmatrix}
\]

Solving the system:
\[
\begin{bmatrix} 2 & 2 & 3 \\ 0 & \sqrt{2} & -\sqrt{2} \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix} 4 \\ -2\sqrt{2} \\ 0 \end{bmatrix}
\]

\textbf{Back Substitution:}
\begin{enumerate}
    \item $1 \cdot x_3 = 0 \implies x_3 = 0$.
    \item $\sqrt{2}x_2 - \sqrt{2}(0) = -2\sqrt{2} \implies x_2 = -2$.
    \item $2x_1 + 2(-2) + 3(0) = 4 \implies 2x_1 - 4 = 4 \implies 2x_1 = 8 \implies x_1 = 4$.
\end{enumerate}

\textbf{Solution:} $\mathbf{x} = [4, -2, 0]^T$.



\section*{Problem 3. (Householder Reï¬‚ection)}

\subsection*{Part 1: Orthonormal Basis}

\paragraph{Step 1: First Householder Reflection ($H_1$)}
We target the first column of $A$, $\vect{x} = A_1 = \begin{bmatrix} 1 \\ -2 \\ 2 \end{bmatrix}$.

First, find its norm:
$$ \|\vect{x}\|_2 = \sqrt{1^2 + (-2)^2 + 2^2} = \sqrt{1 + 4 + 4} = \sqrt{9} = 3 $$

Next, we define the vector $\vect{v}_1$. The problem states to choose the sign $\mp$ to maximize $\|\vect{v}\|_2$.
\begin{itemize}
    \item $\vect{v}_- = \vect{x} - \|\vect{x}\|_2\vect{e}_1 = \begin{bmatrix} 1 \\ -2 \\ 2 \end{bmatrix} - 3\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} = \begin{bmatrix} -2 \\ -2 \\ 2 \end{bmatrix}$. $\|\vect{v}_-\|_2^2 = 4+4+4 = 12$.
    \item $\vect{v}_+ = \vect{x} + \|\vect{x}\|_2\vect{e}_1 = \begin{bmatrix} 1 \\ -2 \\ 2 \end{bmatrix} + 3\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} = \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix}$. $\|\vect{v}_+\|_2^2 = 16+4+4 = 24$.
\end{itemize}
We choose the '+' sign to maximize the norm. So, $\vect{v}_1 = \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix}$, and $\|\vect{v}_1\|_2^2 = 24$.

The Householder reflector is $H_1 = I - 2 \frac{\vect{v}_1 \vect{v}_1^T}{\|\vect{v}_1\|_2^2}$:
$$ \vect{v}_1 \vect{v}_1^T = \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix} \begin{bmatrix} 4 & -2 & 2 \end{bmatrix} = \begin{bmatrix} 16 & -8 & 8 \\ -8 & 4 & -4 \\ 8 & -4 & 4 \end{bmatrix} $$
$$ H_1 = I - \frac{2}{24} \begin{bmatrix} 16 & -8 & 8 \\ -8 & 4 & -4 \\ 8 & -4 & 4 \end{bmatrix} = I - \frac{1}{12} \begin{bmatrix} 16 & -8 & 8 \\ -8 & 4 & -4 \\ 8 & -4 & 4 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} - \begin{bmatrix} 4/3 & -2/3 & 2/3 \\ -2/3 & 1/3 & -1/3 \\ 2/3 & -1/3 & 1/3 \end{bmatrix} $$
$$ H_1 = \begin{bmatrix} -1/3 & 2/3 & -2/3 \\ 2/3 & 2/3 & 1/3 \\ -2/3 & 1/3 & 2/3 \end{bmatrix} = \frac{1}{3} \begin{bmatrix} -1 & 2 & -2 \\ 2 & 2 & 1 \\ -2 & 1 & 2 \end{bmatrix} $$

\paragraph{Step 2: Apply $H_1$ to $A$}
We compute $A^{(1)} = H_1 A$:
$$ A^{(1)} = \frac{1}{3} \begin{bmatrix} -1 & 2 & -2 \\ 2 & 2 & 1 \\ -2 & 1 & 2 \end{bmatrix} \begin{bmatrix} 1 & 1 & -3 \\ -2 & -5 & 20 \\ 2 & 8 & 3 \end{bmatrix} = \frac{1}{3} \begin{bmatrix} -1-4-4 & -1-10-16 & 3+40-6 \\ 2-4+2 & 2-10+8 & -6+40+3 \\ -2-2+4 & -2-5+16 & 6+20+6 \end{bmatrix} $$
$$ A^{(1)} = \frac{1}{3} \begin{bmatrix} -9 & -27 & 37 \\ 0 & 0 & 37 \\ 0 & 9 & 32 \end{bmatrix} = \begin{bmatrix} -3 & -9 & 37/3 \\ 0 & 0 & 37/3 \\ 0 & 3 & 32/3 \end{bmatrix} $$
As expected, the first column below the diagonal is zero.

\paragraph{Step 3: Second Householder Reflection ($H_2$)}
We now work on the $2 \times 2$ submatrix $\begin{bmatrix} 0 & 37/3 \\ 3 & 32/3 \end{bmatrix}$. We want to zero out the $(2,1)$ entry of this submatrix (which is the $(3,2)$ entry of $A^{(1)}$).
Let $\vect{x}' = \begin{bmatrix} 0 \\ 3 \end{bmatrix}$. $\|\vect{x}'\|_2 = 3$.
We choose $\vect{v}' = \vect{x}' + \|\vect{x}'\|_2 \vect{e}_1 = \begin{bmatrix} 0 \\ 3 \end{bmatrix} + 3 \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 3 \\ 3 \end{bmatrix}$.
$\|\vect{v}'\|_2^2 = 9 + 9 = 18$.

The $2 \times 2$ reflector $H'$ is:
$$ H' = I - 2 \frac{\vect{v}' \vect{v}'^T}{\|\vect{v}'\|_2^2} = I - \frac{2}{18} \begin{bmatrix} 3 \\ 3 \end{bmatrix} \begin{bmatrix} 3 & 3 \end{bmatrix} = I - \frac{1}{9} \begin{bmatrix} 9 & 9 \\ 9 & 9 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} - \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} = \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} $$
This is a simple permutation matrix. We embed this into a $3 \times 3$ matrix $H_2$:
$$ H_2 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & -1 & 0 \end{bmatrix} $$
$H_2$ is also orthogonal and symmetric.

\paragraph{Step 4: Find $R$}
The final upper triangular matrix $R$ is $R = H_2 A^{(1)}$:
$$ R = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & -1 & 0 \end{bmatrix} \begin{bmatrix} -3 & -9 & 37/3 \\ 0 & 0 & 37/3 \\ 0 & 3 & 32/3 \end{bmatrix} = \begin{bmatrix} -3 & -9 & 37/3 \\ 0 & -3 & -32/3 \\ 0 & 0 & -37/3 \end{bmatrix} $$

\paragraph{Step 5: Find $Q$}
We have $R = H_2 A^{(1)} = H_2 (H_1 A) = (H_2 H_1) A$.
So, $A = (H_2 H_1)^{-1} R = (H_1^{-1} H_2^{-1}) R$.
Since $H_1$ and $H_2$ are orthogonal and symmetric, $H^{-1} = H^T = H$.
$A = (H_1 H_2) R$. Thus, $Q = H_1 H_2$.
$$ Q = \left( \frac{1}{3} \begin{bmatrix} -1 & 2 & -2 \\ 2 & 2 & 1 \\ -2 & 1 & 2 \end{bmatrix} \right) \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & -1 & 0 \end{bmatrix} = \frac{1}{3} \begin{bmatrix} -1 & 2 & -2 \\ 2 & -1 & -2 \\ -2 & -2 & -1 \end{bmatrix} $$

\paragraph{Conclusion for Part 1}
An orthonormal basis for $R(A)$ is formed by the columns of $Q$:
$$ \left\{ \vect{q}_1, \vect{q}_2, \vect{q}_3 \right\} = \left\{ \frac{1}{3}\begin{bmatrix} -1 \\ 2 \\ -2 \end{bmatrix}, \frac{1}{3}\begin{bmatrix} 2 \\ -1 \\ -2 \end{bmatrix}, \frac{1}{3}\begin{bmatrix} -2 \\ -2 \\ -1 \end{bmatrix} \right\} $$


\subsection*{Part 2: Inverse of $A^T A$}

The "conclusion from 1" is the $QR$ decomposition $A = QR$. We use this to find $(A^T A)^{-1}$.
$$ A^T A = (QR)^T (QR) = R^T Q^T Q R $$
Since $Q$ is orthogonal, $Q^T Q = I$.
$$ A^T A = R^T I R = R^T R $$
Therefore:
$$ (A^T A)^{-1} = (R^T R)^{-1} = R^{-1} (R^T)^{-1} = R^{-1} (R^{-1})^T $$
We first need to find $R^{-1}$ from $R = \begin{bmatrix} -3 & -9 & 37/3 \\ 0 & -3 & -32/3 \\ 0 & 0 & -37/3 \end{bmatrix}$.

We can find the inverse of this upper triangular matrix by back substitution or row reduction.
$$ \left[ \begin{array}{ccc|ccc} -3 & -9 & 37/3 & 1 & 0 & 0 \\ 0 & -3 & -32/3 & 0 & 1 & 0 \\ 0 & 0 & -37/3 & 0 & 0 & 1 \end{array} \right] $$
Scale rows to get 1s on the diagonal:
$$ \left[ \begin{array}{ccc|ccc} 1 & 3 & -37/9 & -1/3 & 0 & 0 \\ 0 & 1 & 32/9 & 0 & -1/3 & 0 \\ 0 & 0 & 1 & 0 & 0 & -3/37 \end{array} \right] $$
$R_1 \to R_1 - 3R_2$:
$$ \left[ \begin{array}{ccc|ccc} 1 & 0 & -133/9 & -1/3 & 1 & 0 \\ 0 & 1 & 32/9 & 0 & -1/3 & 0 \\ 0 & 0 & 1 & 0 & 0 & -3/37 \end{array} \right] $$
$R_1 \to R_1 + \frac{133}{9}R_3$ and $R_2 \to R_2 - \frac{32}{9}R_3$:
$$ \left[ \begin{array}{ccc|ccc} 1 & 0 & 0 & -1/3 & 1 & (133/9)(-3/37) \\ 0 & 1 & 0 & 0 & -1/3 & -(32/9)(-3/37) \\ 0 & 0 & 1 & 0 & 0 & -3/37 \end{array} \right] $$
$$ \left[ \begin{array}{ccc|ccc} 1 & 0 & 0 & -1/3 & 1 & -133/111 \\ 0 & 1 & 0 & 0 & -1/3 & 32/111 \\ 0 & 0 & 1 & 0 & 0 & -9/111 \end{array} \right] $$
So, $R^{-1} = \frac{1}{111} \begin{bmatrix} -37 & 111 & -133 \\ 0 & -37 & 32 \\ 0 & 0 & -9 \end{bmatrix}$.

Now we compute $(A^T A)^{-1} = R^{-1} (R^{-1})^T$:
$$ (R^{-1})^T = \frac{1}{111} \begin{bmatrix} -37 & 0 & 0 \\ 111 & -37 & 0 \\ -133 & 32 & -9 \end{bmatrix} $$
$$ (A^T A)^{-1} = \frac{1}{111^2} \begin{bmatrix} -37 & 111 & -133 \\ 0 & -37 & 32 \\ 0 & 0 & -9 \end{bmatrix} \begin{bmatrix} -37 & 0 & 0 \\ 111 & -37 & 0 \\ -133 & 32 & -9 \end{bmatrix} $$
$$ (A^T A)^{-1} = \frac{1}{12321} \begin{bmatrix} (-37)^2 + 111^2 + (-133)^2 & 111(-37) + (-133)(32) & (-133)(-9) \\ (-37)(111) + 32(-133) & (-37)^2 + 32^2 & 32(-9) \\ (-9)(-133) & (-9)(32) & (-9)^2 \end{bmatrix} $$
$$ (A^T A)^{-1} = \frac{1}{12321} \begin{bmatrix} 1369 + 12321 + 17689 & -4107 - 4256 & 1197 \\ -4107 - 4256 & 1369 + 1024 & -288 \\ 1197 & -288 & 81 \end{bmatrix} $$

\paragraph{Conclusion for Part 2}
The inverse of $A^T A$ is:
$$ (A^T A)^{-1} = \frac{1}{12321} \begin{bmatrix} 31379 & -8363 & 1197 \\ -8363 & 2393 & -288 \\ 1197 & -288 & 81 \end{bmatrix} $$


\section*{Problem 4. (Givens Rotation)}
We will use a sequence of Givens rotations $G_1, G_2, G_3, G_4$ to zero out the sub-diagonal elements of $A$ one by one, resulting in the upper triangular matrix $R$. We have $R = G_4 G_3 G_2 G_1 A$. The orthogonal matrix $Q$ is then given by $Q = (G_4 G_3 G_2 G_1)^T = G_1^T G_2^T G_3^T G_4^T$.

\subsection*{Step 1: Zero out A(4, 1)}
We apply a rotation $G_1$ in the (1, 4)-plane to zero out $A(4, 1) = 2$ using $A(1, 1) = 1$.
Let $a = 1$ and $b = 2$.
$r = \sqrt{a^2 + b^2} = \sqrt{1^2 + 2^2} = \sqrt{5}$
$c = a/r = 1/\sqrt{5}$
$s = b/r = 2/\sqrt{5}$

The rotation matrix $G_1$ is:
$$ G_1 = \begin{bmatrix} c & 0 & 0 & s \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ -s & 0 & 0 & c \end{bmatrix} = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & 2/\sqrt{5} \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ -2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix} $$
We compute $A_1 = G_1 A$:
$$ A_1 = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & 2/\sqrt{5} \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ -2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix} \begin{bmatrix} 1 & 2 & 2 \\ 0 & 1 & 0 \\ 0 & 2 & 2 \\ 2 & 3 & 5 \end{bmatrix} = \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & 1 & 0 \\ 0 & 2 & 2 \\ 0 & -1/\sqrt{5} & 1/\sqrt{5} \end{bmatrix} $$

\subsection*{Step 2: Zero out A\(_1\)(3, 2)}
Next, we apply a rotation $G_2$ in the (2, 3)-plane to zero out $A_1(3, 2) = 2$ using $A_1(2, 2) = 1$.
Let $a = 1$ and $b = 2$.
$r = \sqrt{1^2 + 2^2} = \sqrt{5}$
$c = 1/\sqrt{5}$
$s = 2/\sqrt{5}$

$$ G_2 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & c & s & 0 \\ 0 & -s & c & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1/\sqrt{5} & 2/\sqrt{5} & 0 \\ 0 & -2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} $$
We compute $A_2 = G_2 A_1$:
$$ A_2 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1/\sqrt{5} & 2/\sqrt{5} & 0 \\ 0 & -2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & 1 & 0 \\ 0 & 2 & 2 \\ 0 & -1/\sqrt{5} & 1/\sqrt{5} \end{bmatrix} = \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & \sqrt{5} & 4/\sqrt{5} \\ 0 & 0 & 2/\sqrt{5} \\ 0 & -1/\sqrt{5} & 1/\sqrt{5} \end{bmatrix} $$

\subsection*{Step 3: Zero out A\(_2\)(4, 2)}
We apply a rotation $G_3$ in the (2, 4)-plane to zero out $A_2(4, 2) = -1/\sqrt{5}$ using $A_2(2, 2) = \sqrt{5}$.
Let $a = \sqrt{5}$ and $b = -1/\sqrt{5}$.
$r = \sqrt{(\sqrt{5})^2 + (-1/\sqrt{5})^2} = \sqrt{5 + 1/5} = \sqrt{26/5}$
$c = a/r = \sqrt{5} / \sqrt{26/5} = 5/\sqrt{26}$
$s = b/r = (-1/\sqrt{5}) / \sqrt{26/5} = -1/\sqrt{26}$

$$ G_3 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & c & 0 & s \\ 0 & 0 & 1 & 0 \\ 0 & -s & 0 & c \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 5/\sqrt{26} & 0 & -1/\sqrt{26} \\ 0 & 0 & 1 & 0 \\ 0 & 1/\sqrt{26} & 0 & 5/\sqrt{26} \end{bmatrix} $$
We compute $A_3 = G_3 A_2$:
$$ A_3 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 5/\sqrt{26} & 0 & -1/\sqrt{26} \\ 0 & 0 & 1 & 0 \\ 0 & 1/\sqrt{26} & 0 & 5/\sqrt{26} \end{bmatrix} \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & \sqrt{5} & 4/\sqrt{5} \\ 0 & 0 & 2/\sqrt{5} \\ 0 & -1/\sqrt{5} & 1/\sqrt{5} \end{bmatrix} = \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & \sqrt{26/5} & 19/\sqrt{130} \\ 0 & 0 & 2/\sqrt{5} \\ 0 & 0 & 9/\sqrt{130} \end{bmatrix} $$

\subsection*{Step 4: Zero out A\(_3\)(4, 3)}
Finally, we apply a rotation $G_4$ in the (3, 4)-plane to zero out $A_3(4, 3) = 9/\sqrt{130}$ using $A_3(3, 3) = 2/\sqrt{5}$.
Let $a = 2/\sqrt{5}$ and $b = 9/\sqrt{130}$.
$r = \sqrt{(2/\sqrt{5})^2 + (9/\sqrt{130})^2} = \sqrt{4/5 + 81/130} = \sqrt{(104+81)/130} = \sqrt{185/130} = \sqrt{37/26}$
$c = a/r = (2/\sqrt{5}) / \sqrt{185/130} = 2\sqrt{26}/\sqrt{185}$
$s = b/r = (9/\sqrt{130}) / \sqrt{185/130} = 9/\sqrt{185}$

$$ G_4 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & c & s \\ 0 & 0 & -s & c \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 2\sqrt{26}/\sqrt{185} & 9/\sqrt{185} \\ 0 & 0 & -9/\sqrt{185} & 2\sqrt{26}/\sqrt{185} \end{bmatrix} $$
We compute $R = G_4 A_3$:
$$ R = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & c & s \\ 0 & 0 & -s & c \end{bmatrix} \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & \sqrt{26/5} & 19/\sqrt{130} \\ 0 & 0 & 2/\sqrt{5} \\ 0 & 0 & 9/\sqrt{130} \end{bmatrix} = \begin{bmatrix} \sqrt{5} & 8/\sqrt{5} & 12/\sqrt{5} \\ 0 & \sqrt{26/5} & 19/\sqrt{130} \\ 0 & 0 & \sqrt{185/130} \\ 0 & 0 & 0 \end{bmatrix} $$
This gives our upper triangular matrix $R$.

\subsection*{Final Matrix R}
Rationalizing the denominators, $R$ is:
$$ R = \begin{bmatrix}
\sqrt{5} & \frac{8\sqrt{5}}{5} & \frac{12\sqrt{5}}{5} \\
0 & \frac{\sqrt{130}}{5} & \frac{19\sqrt{130}}{130} \\
0 & 0 & \frac{\sqrt{962}}{26} \\
0 & 0 & 0
\end{bmatrix} $$

\subsection*{Finding the Matrix Q}
Now we find $Q = G_1^T G_2^T G_3^T G_4^T$.
$$ G_1^T = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & -2/\sqrt{5} \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix}, \quad G_2^T = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1/\sqrt{5} & -2/\sqrt{5} & 0 \\ 0 & 2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} $$
$$ G_3^T = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 5/\sqrt{26} & 0 & 1/\sqrt{26} \\ 0 & 0 & 1 & 0 \\ 0 & -1/\sqrt{26} & 0 & 5/\sqrt{26} \end{bmatrix}, \quad G_4^T = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & \frac{2\sqrt{26}}{\sqrt{185}} & \frac{-9}{\sqrt{185}} \\ 0 & 0 & \frac{9}{\sqrt{185}} & \frac{2\sqrt{26}}{\sqrt{185}} \end{bmatrix} $$
First, compute $Q' = G_1^T G_2^T$:
$$ Q' = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & -2/\sqrt{5} \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1/\sqrt{5} & -2/\sqrt{5} & 0 \\ 0 & 2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & -2/\sqrt{5} \\ 0 & 1/\sqrt{5} & -2/\sqrt{5} & 0 \\ 0 & 2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix} $$
Next, compute $Q'' = Q' G_3^T$:
$$ Q'' = \begin{bmatrix} 1/\sqrt{5} & 0 & 0 & -2/\sqrt{5} \\ 0 & 1/\sqrt{5} & -2/\sqrt{5} & 0 \\ 0 & 2/\sqrt{5} & 1/\sqrt{5} & 0 \\ 2/\sqrt{5} & 0 & 0 & 1/\sqrt{5} \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 5/\sqrt{26} & 0 & 1/\sqrt{26} \\ 0 & 0 & 1 & 0 \\ 0 & -1/\sqrt{26} & 0 & 5/\sqrt{26} \end{bmatrix} = \begin{bmatrix} 1/\sqrt{5} & 2/\sqrt{130} & 0 & -10/\sqrt{130} \\ 0 & 5/\sqrt{130} & -2/\sqrt{5} & 1/\sqrt{130} \\ 0 & 10/\sqrt{130} & 1/\sqrt{5} & 2/\sqrt{130} \\ 2/\sqrt{5} & -1/\sqrt{130} & 0 & 5/\sqrt{130} \end{bmatrix} $$
Finally, compute $Q = Q'' G_4^T$. This multiplication only affects columns 3 and 4.
\begin{align*}
Q_{\text{col} 3} &= Q''_{\text{col} 3} \cdot c + Q''_{\text{col} 4} \cdot s \\
&= \begin{bmatrix} 0 \\ -2/\sqrt{5} \\ 1/\sqrt{5} \\ 0 \end{bmatrix} \frac{2\sqrt{26}}{\sqrt{185}} + \begin{bmatrix} -10/\sqrt{130} \\ 1/\sqrt{130} \\ 2/\sqrt{130} \\ 5/\sqrt{130} \end{bmatrix} \frac{9}{\sqrt{185}}
= \begin{bmatrix} -90/\sqrt{24050} \\ -95/\sqrt{24050} \\ 70/\sqrt{24050} \\ 45/\sqrt{24050} \end{bmatrix}
= \begin{bmatrix} -18/\sqrt{962} \\ -19/\sqrt{962} \\ 14/\sqrt{962} \\ 9/\sqrt{962} \end{bmatrix}
\end{align*}
\begin{align*}
Q_{\text{col} 4} &= Q''_{\text{col} 3} \cdot (-s) + Q''_{\text{col} 4} \cdot c \\
&= \begin{bmatrix} 0 \\ -2/\sqrt{5} \\ 1/\sqrt{5} \\ 0 \end{bmatrix} \frac{-9}{\sqrt{185}} + \begin{bmatrix} -10/\sqrt{130} \\ 1/\sqrt{130} \\ 2/\sqrt{130} \\ 5/\sqrt{130} \end{bmatrix} \frac{2\sqrt{26}}{\sqrt{185}}
= \begin{bmatrix} -20\sqrt{26}/\sqrt{24050} \\ 20\sqrt{26}/\sqrt{24050} \\ -5\sqrt{26}/\sqrt{24050} \\ 10\sqrt{26}/\sqrt{24050} \end{bmatrix}
= \begin{bmatrix} -4/\sqrt{37} \\ 4/\sqrt{37} \\ -1/\sqrt{37} \\ 2/\sqrt{37} \end{bmatrix}
\end{align*}

\subsection*{Final Matrix Q}
Combining the columns and rationalizing the denominators (noting $962 = 2 \cdot 13 \cdot 37$ and $481 = 13 \cdot 37$):
$$ Q = \begin{bmatrix}
1/\sqrt{5} & 2/\sqrt{130} & -18/\sqrt{962} & -4/\sqrt{37} \\
0 & 5/\sqrt{130} & -19/\sqrt{962} & 4/\sqrt{37} \\
0 & 10/\sqrt{130} & 14/\sqrt{962} & -1/\sqrt{37} \\
2/\sqrt{5} & -1/\sqrt{130} & 9/\sqrt{962} & 2/\sqrt{37}
\end{bmatrix}
=
\begin{bmatrix}
\frac{\sqrt{5}}{5} & \frac{\sqrt{130}}{65} & \frac{-9\sqrt{962}}{481} & \frac{-4\sqrt{37}}{37} \\
0 & \frac{\sqrt{130}}{26} & \frac{-19\sqrt{962}}{962} & \frac{4\sqrt{37}}{37} \\
0 & \frac{\sqrt{130}}{13} & \frac{7\sqrt{962}}{481} & \frac{-\sqrt{37}}{37} \\
\frac{2\sqrt{5}}{5} & \frac{-\sqrt{130}}{130} & \frac{9\sqrt{962}}{962} & \frac{2\sqrt{37}}{37}
\end{bmatrix}
$$


\section*{Problem 5. (QR decomposition)}

This inequality is known as \textbf{Hadamard's inequality}. We will prove it using the QR decomposition, as suggested by the problem context.

\begin{enumerate}
    \item \textbf{QR Decomposition} \\
    Let $A = QR$ be the QR decomposition of the (square) matrix $A$.
    \begin{itemize}
        \item $Q$ is an $n \times n$ orthogonal matrix, which means $Q^T Q = I$ and $Q^{-1} = Q^T$.
        \item $R$ is an $n \times n$ upper triangular matrix.
    \end{itemize}

    \item \textbf{Determinant of A} \\
    We begin by taking the absolute value of the determinant of $A$:
    $$
    |\det(A)| = |\det(QR)| = |\det(Q) \det(R)| = |\det(Q)| |\det(R)|
    $$
    
    \item \textbf{Determinant of Q} \\
    Since $Q$ is orthogonal, we know $Q^T Q = I$. Taking the determinant of both sides:
    $$
    \det(Q^T Q) = \det(I)
    $$
    $$
    \det(Q^T) \det(Q) = 1
    $$
    Since $\det(Q^T) = \det(Q)$, this gives $(\det(Q))^2 = 1$, which implies $|\det(Q)| = 1$.
    
    \item \textbf{Simplifying the Determinant} \\
    Substituting $|\det(Q)| = 1$ back into our equation from Step 2, we get:
    $$
    |\det(A)| = 1 \cdot |\det(R)| = |\det(R)|
    $$

    \item \textbf{Determinant of R} \\
    Since $R$ is an upper triangular matrix, its determinant is the product of its diagonal entries. Let $r_{ii}$ be the diagonal entries of $R$.
    $$
    \det(R) = r_{11} r_{22} \cdots r_{nn}
    $$
    Therefore,
    $$
    |\det(A)| = |r_{11} r_{22} \cdots r_{nn}| = |r_{11}| |r_{22}| \cdots |r_{nn}|
    $$
    
    \item \textbf{Relating $R$ to $A$'s Columns} \\
    From $A = QR$, we can look at the $i$-th column of $A$, which is $\mathbf{a}_i$. This column is the result of $Q$ multiplying the $i$-th column of $R$, which we will call $\mathbf{r}_i$.
    $$
    \mathbf{a}_i = Q \mathbf{r}_i
    $$
    Now, let's find the 2-norm (Euclidean length) of $\mathbf{a}_i$. Because $Q$ is an orthogonal matrix, it preserves the 2-norm (i.e., it is an isometry).
    $$
    \|\mathbf{a}_i\|_2^2 = \mathbf{a}_i^T \mathbf{a}_i = (Q \mathbf{r}_i)^T (Q \mathbf{r}_i) = \mathbf{r}_i^T Q^T Q \mathbf{r}_i = \mathbf{r}_i^T I \mathbf{r}_i = \mathbf{r}_i^T \mathbf{r}_i = \|\mathbf{r}_i\|_2^2
    $$
    Thus, $\|\mathbf{a}_i\|_2 = \|\mathbf{r}_i\|_2$.

    \item \textbf{Norm of $R$'s Columns} \\
    Because $R$ is upper triangular, its $i$-th column $\mathbf{r}_i$ only has non-zero entries in the first $i$ positions.
    $$
    \mathbf{r}_i = \begin{pmatrix} r_{1i} \\ r_{2i} \\ \vdots \\ r_{ii} \\ 0 \\ \vdots \\ 0 \end{pmatrix}
    $$
    The squared norm of $\mathbf{r}_i$ is the sum of the squares of its components:
    $$
    \|\mathbf{r}_i\|_2^2 = |r_{1i}|^2 + |r_{2i}|^2 + \cdots + |r_{ii}|^2
    $$
    
    \item \textbf{The Key Inequality} \\
    From Step 6 and Step 7, we can equate the squared norms:
    $$
    \|\mathbf{a}_i\|_2^2 = |r_{1i}|^2 + |r_{2i}|^2 + \cdots + |r_{ii}|^2
    $$
    Since all the terms in the sum are non-negative (as they are squares), this sum must be greater than or equal to any single term in it. In particular, it must be greater than or equal to the last non-zero term, $|r_{ii}|^2$.
    $$
    \|\mathbf{a}_i\|_2^2 \ge |r_{ii}|^2
    $$
    Taking the square root of both sides (and knowing norms are non-negative):
    $$
    \|\mathbf{a}_i\|_2 \ge |r_{ii}|
    $$
    This holds for all $i = 1, \ldots, n$.

    \item \textbf{Final Assembly} \\
    We now return to our determinant equation from Step 5 and apply the inequality from Step 8 for each term in the product.
    $$
    |\det(A)| = |r_{11}| |r_{22}| \cdots |r_{nn}|
    $$
    Since $\|\mathbf{a}_1\|_2 \ge |r_{11}|$, $\|\mathbf{a}_2\|_2 \ge |r_{22}|$, and so on, we can substitute them:
    $$
    |\det(A)| \le \|\mathbf{a}_1\|_2 \|\mathbf{a}_2\|_2 \cdots \|\mathbf{a}_n\|_2
    $$
    
\end{enumerate}

This completes the proof.
\hfill $\Box$

\end{document}
